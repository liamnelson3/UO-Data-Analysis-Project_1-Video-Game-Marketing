{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, element\n",
    "import urllib\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 1\n",
      "1 Fetch data for game Pokemon\n",
      "2 Fetch data for game Super Mario\n",
      "3 Fetch data for game Call of Duty\n",
      "4 Fetch data for game Grand Theft Auto\n",
      "5 Fetch data for game FIFA\n",
      "6 Fetch data for game Minecraft\n",
      "7 Fetch data for game Minecraft\n",
      "8 Fetch data for game Lego\n",
      "9 Fetch data for game Assassin's Creed\n"
     ]
    }
   ],
   "source": [
    "pages = 2\n",
    "rec_count = 0\n",
    "rank = []\n",
    "gname = []\n",
    "platform = []\n",
    "year = []\n",
    "genre = []\n",
    "critic_score = []\n",
    "user_score = []\n",
    "publisher = []\n",
    "developer = []\n",
    "sales_na = []\n",
    "sales_pal = []\n",
    "sales_jp = []\n",
    "sales_ot = []\n",
    "sales_gl = []\n",
    "# new list to hold href url_to_game\n",
    "ind_game_url = []\n",
    "#altered_ind_game_url = []\n",
    "# new list(s) to hold supplementary sales data according to the new plan\n",
    "#ind_sales_na = []\n",
    "#ind_sales_pal = []\n",
    "#ind_sales_jp = []\n",
    "#ind_sales_ot = []\n",
    "#ind_sales_gl = []\n",
    "\n",
    "\n",
    "# updated url tails to account for order, order = TotalSales\n",
    "# deselecting VGChartz Score\n",
    "urlhead = 'http://www.vgchartz.com/gamedb/?page='\n",
    "urltail = '&console=&region=All&developer=&publisher=&genre=&boxart=Both&ownership=Both'\n",
    "# setting to 10 for test, otherwise 1000\n",
    "urltail += '&results=10&order=Sales&showtotalsales=0&showtotalsales=1&showpublisher=0'\n",
    "urltail += '&showpublisher=1&showvgchartzscore=0&shownasales=1&showdeveloper=1&showcriticscore=1'\n",
    "urltail += '&showpalsales=0&showpalsales=1&showreleasedate=1&showuserscore=1&showjapansales=1'\n",
    "urltail += '&showlastupdate=0&showothersales=1&showgenre=1&sort=GL'\n",
    "\n",
    "\n",
    "\n",
    "for page in range(1, pages):\n",
    "    surl = urlhead + str(page) + urltail\n",
    "    # urllib error, no att request\n",
    "    r = urllib.request.urlopen(surl, data = None).read()\n",
    "    # add features = html.parser\n",
    "    soup = BeautifulSoup(r,features = \"html.parser\" )\n",
    "    print(f\"Page: {page}\")\n",
    "\n",
    "    # page is being scanned for any links that contain the game link\n",
    "    # <a> tags with game urls\n",
    "    # swapped to https\n",
    "    game_tags = list(filter(\n",
    "        lambda x: 'href' in x.attrs and x.attrs['href'].startswith('https://www.vgchartz.com/game/'),\n",
    "        # discard the first 10 elements because those\n",
    "        # links are in the navigation bar\n",
    "        soup.find_all(\"a\")\n",
    "    ))[1:]\n",
    "\n",
    "    for tag in game_tags:\n",
    "        \n",
    "        # add name to list\n",
    "        gname.append(\" \".join(tag.string.split()))\n",
    "        print(f\"{rec_count + 1} Fetch data for game {gname[-1]}\")\n",
    "\n",
    "        # get different attributes\n",
    "        # traverse up the DOM tree\n",
    "        data = tag.parent.parent.find_all(\"td\")\n",
    "        rank.append(np.int32(data[0].string))\n",
    "        platform.append(data[3].find('img').attrs['alt'])\n",
    "        publisher.append(data[4].string)\n",
    "        developer.append(data[5].string)\n",
    "        critic_score.append(\n",
    "            float(data[6].string) if\n",
    "            not data[6].string.startswith(\"N/A\") else np.nan)\n",
    "        user_score.append(\n",
    "            float(data[7].string) if\n",
    "            not data[7].string.startswith(\"N/A\") else np.nan)\n",
    "        # most of the sales data that was indicated on the website is now populating as N/A\n",
    "        # I think it's mostly an issue with how the main GameDB table is populating, reason being\n",
    "        # if you click on each individual game url and navigate to the sales tab, the sales data is there, it exists\n",
    "        # so, new plan:\n",
    "        # in the same vein of when we grab the genre info, by detecting and reading each individual game url\n",
    "        # we ALSO take those urls, chop of their tails, add the word sales and form a new GET request\n",
    "        sales_na.append(\n",
    "            float(data[9].string[:-1]) if\n",
    "            not data[9].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_pal.append(\n",
    "            float(data[10].string[:-1]) if\n",
    "            not data[10].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_jp.append(\n",
    "            float(data[11].string[:-1]) if\n",
    "            not data[11].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_ot.append(\n",
    "            float(data[12].string[:-1]) if\n",
    "            not data[12].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_gl.append(\n",
    "            float(data[8].string[:-1]) if\n",
    "            not data[8].string.startswith(\"N/A\") else np.nan)\n",
    "        release_year = data[13].string.split()[-1]\n",
    "        # different format for year\n",
    "        if release_year.startswith('N/A'):\n",
    "            year.append('N/A')\n",
    "        else:\n",
    "            if int(release_year) >= 80:\n",
    "                year_to_add = np.int32(\"19\" + release_year)\n",
    "            else:\n",
    "                year_to_add = np.int32(\"20\" + release_year)\n",
    "            year.append(year_to_add)\n",
    "\n",
    "        # go to every individual website to get genre info\n",
    "        url_to_game = tag.attrs['href']\n",
    "        site_raw = urllib.request.urlopen(url_to_game).read()\n",
    "        sub_soup = BeautifulSoup(site_raw, \"html.parser\")\n",
    "        # again, the info box is inconsistent among games so we\n",
    "        # have to find all the h2 and traverse from that to the genre name\n",
    "        h2s = sub_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"}).find_all('h2')\n",
    "        # make a temporary tag here to search for the one that contains\n",
    "        # the word \"Genre\"\n",
    "        temp_tag = element.Tag\n",
    "        for h2 in h2s:\n",
    "            if h2.string == 'Genre':\n",
    "                temp_tag = h2\n",
    "        genre.append(temp_tag.next_sibling.string)\n",
    "\n",
    "        # new plan taketh shape\n",
    "        # individual game url column\n",
    "        ind_game_url.append(url_to_game)\n",
    "        # new tail piece that will take us to the sales page of each game\n",
    "       # new_tail = \"sales\"\n",
    "       # last_slash_index = ind_game_url.rfind('/')\n",
    "       # for tails\n",
    "\n",
    "\n",
    "        rec_count += 1\n",
    "\n",
    "columns = {\n",
    "    'Rank': rank,\n",
    "    'Name': gname,\n",
    "    'Platform': platform,\n",
    "    'Year': year,\n",
    "    'Genre': genre,\n",
    "    'Critic_Score': critic_score,\n",
    "    'User_Score': user_score,\n",
    "    'Publisher': publisher,\n",
    "    'Developer': developer,\n",
    "    'NA_Sales': sales_na,\n",
    "    'PAL_Sales': sales_pal,\n",
    "    'JP_Sales': sales_jp,\n",
    "    'Other_Sales': sales_ot,\n",
    "    'Global_Sales': sales_gl,\n",
    "    'Game_URL': ind_game_url\n",
    "}\n",
    "   #'Ind_NA_Sales': ind_sales_na,\n",
    "    #'Ind_PAL_Sales': ind_sales_pal,\n",
    "    #'Ind_JP_Sales': ind_sales_jp,\n",
    "    #'Ind_Other_Sales': ind_sales_ot,\n",
    "    #'Ind_Global_Sales': ind_sales_gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Index(['Rank', 'Name', 'Platform', 'Year', 'Genre', 'Critic_Score',\n",
      "       'User_Score', 'Publisher', 'Developer', 'NA_Sales', 'PAL_Sales',\n",
      "       'JP_Sales', 'Other_Sales', 'Global_Sales', 'Game_URL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(rec_count)\n",
    "df = pd.DataFrame(columns)\n",
    "print(df.columns)\n",
    "df = df[[\n",
    "    'Rank', 'Name', 'Platform', 'Year', 'Genre',\n",
    "    'Publisher', 'Developer', 'Critic_Score', 'User_Score',\n",
    "    'NA_Sales', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales',\n",
    "    'Game_URL']]\n",
    "\n",
    "#'Ind_NA_Sales', 'Ind_PAL_Sales', 'Ind_JP_Sales', 'Ind_Other_Sales', 'Ind_Global_Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of the file\n",
    "df.to_csv(os.getcwd()+r\"\\vgsales_xx.csv\", sep=\",\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
