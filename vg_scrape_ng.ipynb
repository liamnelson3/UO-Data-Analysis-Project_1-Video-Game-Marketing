{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, element\n",
    "import urllib\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = 9\n",
    "rec_count = 0\n",
    "rank = []\n",
    "gname = []\n",
    "platform = []\n",
    "year = []\n",
    "genre = []\n",
    "critic_score = []\n",
    "user_score = []\n",
    "publisher = []\n",
    "developer = []\n",
    "sales_na = []\n",
    "sales_pal = []\n",
    "sales_jp = []\n",
    "sales_ot = []\n",
    "sales_gl = []\n",
    "# new list to hold href url_to_game\n",
    "ind_game_url = []\n",
    "modified_ind_game_url=[]\n",
    "ind_sales_gl = []\n",
    "\n",
    "\n",
    "\n",
    "# deselecting VGChartz Score\n",
    "urlhead = 'http://www.vgchartz.com/gamedb/?page='\n",
    "urltail = '&console=&region=All&developer=&publisher=&genre=&boxart=Both&ownership=Both'\n",
    "urltail += '&results=1000&order=TotalSales&showtotalsales=1&showtotalsales=1&showpublisher=0'\n",
    "urltail += '&showpublisher=1&showvgchartzscore=0&shownasales=1&showdeveloper=1&showcriticscore=1'\n",
    "urltail += '&showpalsales=0&showpalsales=1&showreleasedate=1&showuserscore=1&showjapansales=1'\n",
    "urltail += '&showlastupdate=0&showothersales=1&showgenre=1&sort=GL'\n",
    "\n",
    "\n",
    "\n",
    "for page in range(1, pages):\n",
    "    url = urlhead + str(page) + urltail\n",
    "    \n",
    "    \n",
    "    # urllib error, no att request\n",
    "    data = urllib.request.urlopen(surl, data = None).read()\n",
    "    # add features = html.parser\n",
    "\n",
    "    data = urllib.request.urlopen(url, data = None).read()\n",
    "    soup = BeautifulSoup(data,features = \"html.parser\" )\n",
    "\n",
    "\n",
    "    print(f\"Page: {page}\")\n",
    "\n",
    "    # page scan for individual game links\n",
    "    # <a> tags with game urls\n",
    "    # swapped to https\n",
    "    game_tags = list(filter(\n",
    "        lambda x: 'href' in x.attrs and x.attrs['href'].startswith('https://www.vgchartz.com/game/'),\n",
    "        # skipping the first link as it's being tied to navigation\n",
    "        soup.find_all(\"a\")\n",
    "    ))[1:]\n",
    "\n",
    "    for tag in game_tags:\n",
    "        \n",
    "        # add name to list\n",
    "        gname.append(\" \".join(tag.string.split()))\n",
    "        print(f\"{rec_count + 1} Fetch data for game {gname[-1]}\")\n",
    "\n",
    "        # get different attributes\n",
    "        # traverse up the DOM tree\n",
    "        data = tag.parent.parent.find_all(\"td\")\n",
    "        rank.append(np.int32(data[0].string))\n",
    "        platform.append(data[3].find('img').attrs['alt'])\n",
    "        publisher.append(data[4].string)\n",
    "        developer.append(data[5].string)\n",
    "        critic_score.append(\n",
    "            float(data[6].string) if\n",
    "            not data[6].string.startswith(\"N/A\") else np.nan)\n",
    "        user_score.append(\n",
    "            float(data[7].string) if\n",
    "            not data[7].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_na.append(\n",
    "            float(data[9].string[:-1]) if\n",
    "            not data[9].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_pal.append(\n",
    "            float(data[10].string[:-1]) if\n",
    "            not data[10].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_jp.append(\n",
    "            float(data[11].string[:-1]) if\n",
    "            not data[11].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_ot.append(\n",
    "            float(data[12].string[:-1]) if\n",
    "            not data[12].string.startswith(\"N/A\") else np.nan)\n",
    "        sales_gl.append(\n",
    "            float(data[8].string[:-1]) if\n",
    "            not data[8].string.startswith(\"N/A\") else np.nan)\n",
    "        release_year = data[13].string.split()[-1]\n",
    "        # different format for year\n",
    "        if release_year.startswith('N/A'):\n",
    "            year.append('N/A')\n",
    "        else:\n",
    "            if int(release_year) >= 80:\n",
    "                year_to_add = np.int32(\"19\" + release_year)\n",
    "            else:\n",
    "                year_to_add = np.int32(\"20\" + release_year)\n",
    "            year.append(year_to_add)\n",
    "\n",
    "        # go to every individual website to get genre info\n",
    "        url_to_game = tag.attrs['href']\n",
    "        site_raw = urllib.request.urlopen(url_to_game).read()\n",
    "        sub_soup = BeautifulSoup(site_raw, \"html.parser\")\n",
    "        # again, the info box is inconsistent among games so we\n",
    "        # have to find all the h2 and traverse from that to the genre name\n",
    "        h2s = sub_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"}).find_all('h2')\n",
    "        # make a temporary tag here to search for the one that contains\n",
    "        # the word \"Genre\"\n",
    "        temp_tag = element.Tag\n",
    "        for h2 in h2s:\n",
    "            if h2.string == 'Genre':\n",
    "                temp_tag = h2\n",
    "        genre.append(temp_tag.next_sibling.string)\n",
    "\n",
    "        # new plan\n",
    "        ind_game_url.append(url_to_game)\n",
    "\n",
    "\n",
    "        rec_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new tail piece for ind_game_url\n",
    "new_tail = \"sales\"\n",
    "for i in range(len(ind_game_url)):\n",
    "    url = ind_game_url[i]\n",
    "    last_slash_index = url.rfind('/')\n",
    "    if last_slash_index != -1:\n",
    "        modified_ind_game_url = url[:last_slash_index + 1] + new_tail\n",
    "        ind_game_url[i] = modified_ind_game_url\n",
    "        print(modified_ind_game_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with our modified individual individual game urls (modified_ind_game_url)\n",
    "# create a loop that feeds the list into soup_sales\n",
    "for j in range(len(modified_ind_game_url)):\n",
    "    site_sales = urllib.request.urlopen(modified_ind_game_url).read()\n",
    "    soup_sales = BeautifulSoup(site_sales, \"html.parser\")\n",
    "    br_total = soup_sales.find(\"td\", {\"id\": \"salesHistoryHeaderB\"}).find_all('b')\n",
    "    # make a temporary tag here to search for the one that contains\n",
    "    # the word \"Total\"\n",
    "    tag_sales_total = element.Tag\n",
    "    for b in br_total:\n",
    "        if b.string == 'Total':\n",
    "            tag_sales_total = b\n",
    "            ind_sales_gl.append(tag_sales_total.previous_sibling.previous_sibling.string)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'Rank': rank,\n",
    "    'Name': gname,\n",
    "    'Platform': platform,\n",
    "    'Year': year,\n",
    "    'Genre': genre,\n",
    "    'Critic_Score': critic_score,\n",
    "    'User_Score': user_score,\n",
    "    'Publisher': publisher,\n",
    "    'Developer': developer,\n",
    "    'NA_Sales': sales_na,\n",
    "    'PAL_Sales': sales_pal,\n",
    "    'JP_Sales': sales_jp,\n",
    "    'Other_Sales': sales_ot,\n",
    "    'Global_Sales': sales_gl,\n",
    "    'Game_URL': ind_game_url,\n",
    "    'Sales_Game_URL': modified_ind_game_url,\n",
    "    'Ind_Global_Sales': ind_sales_gl\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rec_count)\n",
    "df = pd.DataFrame(columns)\n",
    "print(df.columns)\n",
    "df = df[[\n",
    "    'Rank', 'Name', 'Platform', 'Year', 'Genre',\n",
    "    'Publisher', 'Developer', 'Critic_Score', 'User_Score',\n",
    "    'NA_Sales', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales',\n",
    "    'Game_URL', 'Sales_Game_URL','Ind_Global_Sales']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of the file\n",
    "df.to_csv(os.getcwd()+r\"\\vgsales_xx.csv\", sep=\",\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
